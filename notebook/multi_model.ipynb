{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Translate using a multiple models and a translation matrix\n",
    "# Uses a translation matrix to convert the word-vector from one language to the other \n",
    "# i.e. vec(\"koning\")*matrix = vec(\"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import getopt\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "from utils import read_dict, train_tm, apply_tm, score, get_valid_data\n",
    "from tsne import bh_sne\n",
    "import csv\n",
    "import codecs\n",
    "import unicodedata\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to run with two seperate models:\n",
    "#model_nl = Word2Vec.load_word2vec_format('models/nlwiki_lowercase.model', binary=False)  # C text format\n",
    "#model_en = Word2Vec.load_word2vec_format('models/enwiki_lowercase.model', binary=False, encoding='latin1')  # C text format\n",
    "# We also did it with different test sets\n",
    "#model_nl = Word2Vec.load_word2vec_format('models/nlwiki_lowercase_400.model', binary=False)  # C text format\n",
    "# model_en = Word2Vec.load_word2vec_format('models/enwiki_lowercase_400.model', binary=False, encoding='latin1')  # C text format\n",
    "\n",
    "# If you want to run with a single model that's used for both input and output\n",
    "#model_both = Word2Vec.load_word2vec_format('models/bothwiki_lowercase_400.model', binary=False, encoding='latin1')  # C text format\n",
    "model_both = Word2Vec.load_word2vec_format('models/bothwiki_lowercase.model', binary=False, encoding='latin1')  # C text format\n",
    "\n",
    "# Instead of loading two separate models, store this model in both variables\n",
    "model_nl = model_both\n",
    "model_en = model_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 500, Accuracy @1, 5, 10: [0.52623396813058687, 0.62261951029926155, 0.66342790516906336]\n",
      "Training Size: 500, Accuracy @1, 5, 10: [0.5273999222697241, 0.62261951029926155, 0.6618732996502138]\n",
      "Training Size: 500, Accuracy @1, 5, 10: [0.52895452778857366, 0.62611737271667312, 0.6723668869024485]\n",
      "Training Size: 500, Accuracy @1, 5, 10: [0.52623396813058687, 0.62145355616012432, 0.65215701515740376]\n",
      "Training Size: 500, Accuracy @1, 5, 10: [0.52467936261173731, 0.62844928099494757, 0.6657598134473377]\n",
      "Training Size: 500, Accuracy @1, 5, 10: [0.51574038087835217, 0.6183443451224252, 0.66498251068791292]\n",
      "Training Size: 500, Accuracy @1, 5, 10: [0.54955305091333073, 0.64049747376603183, 0.68169452001554609]\n",
      "Training Size: 500, Accuracy @1, 5, 10: [0.5227361057131753, 0.62611737271667312, 0.6657598134473377]\n",
      "Training Size: 500, Accuracy @1, 5, 10: [0.51768363777691406, 0.6136805285658764, 0.64827050136027986]\n",
      "Training Size: 500, Accuracy @1, 5, 10: [0.52856587640886121, 0.63505635445005826, 0.67158958414302372]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.53740396279822078, 0.64617873028710071, 0.67974120501415281]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.53902143145976544, 0.63526081682167412, 0.67286696320258799]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.53861706429437928, 0.63162151233319852, 0.67003639304488471]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.54468257177517188, 0.64375252729478372, 0.67852810351799431]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.54508693894055804, 0.62959967650626769, 0.67448443186413265]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.53093408815204202, 0.64375252729478372, 0.67731500202183581]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.54993934492519203, 0.64375252729478372, 0.67610190052567731]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.53902143145976544, 0.63890012131014962, 0.67691063485644964]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.53416902547513145, 0.62959967650626769, 0.67165386170642949]\n",
      "Training Size: 600, Accuracy @1, 5, 10: [0.54306510311362721, 0.63930448847553578, 0.67529316619490498]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.55077960387694902, 0.65023177412557942, 0.68942267172355665]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.54530130636325325, 0.64348925410872315, 0.67635903919089757]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.54614412136536028, 0.64433206911083019, 0.6797302991993257]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.54909397387273495, 0.64728192161820486, 0.68478718921196802]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.54403708386009275, 0.63295406658238518, 0.67088074167720191]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.54403708386009275, 0.63168984407922457, 0.67593763168984411]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.55541508638853776, 0.64643910661609771, 0.68520859671302148]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.56468605141171513, 0.65571007163927519, 0.69110830172777071]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.55667930889169825, 0.64854614412136535, 0.68057311420143274]\n",
      "Training Size: 700, Accuracy @1, 5, 10: [0.54277286135693215, 0.64053940160134848, 0.67804466919511164]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.55345358556973168, 0.65112186537615491, 0.68939727232732073]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.56005279366476024, 0.64716234051913768, 0.68323801143862739]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.55169379674439067, 0.64848218213814346, 0.68895732512098551]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.54773427188737356, 0.64232292124945012, 0.68499780026396828]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.56445226572811258, 0.66168059832820059, 0.69511658600967885]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.55125384953805545, 0.65068191816981957, 0.68587769467663884]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.55741311042674879, 0.65684117905851302, 0.69467663880334363]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.54113506379234488, 0.63352397712274522, 0.67311922569291682]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.56269247690277169, 0.65904091509018914, 0.69379674439067307]\n",
      "Training Size: 800, Accuracy @1, 5, 10: [0.55345358556973168, 0.64672239331280246, 0.68103827540695117]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.54855039116428905, 0.6465715600552232, 0.68476760239300505]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.54901058444546713, 0.64104924068108604, 0.67602393005062122]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.55407271053842611, 0.64611136677404513, 0.68384721583064889]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.55085135757017945, 0.65807639208467561, 0.69351127473538887]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.55131155085135752, 0.64795213989875744, 0.69121030832949837]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.56511734928670043, 0.65761619880349742, 0.69489185457892311]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.56189599631845377, 0.65761619880349742, 0.69167050161067645]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.56833870225494709, 0.65577542567878511, 0.69028992176714221]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.55913483663138519, 0.65025310630464794, 0.69028992176714221]\n",
      "Training Size: 900, Accuracy @1, 5, 10: [0.55085135757017945, 0.65025310630464794, 0.69028992176714221]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.56246985045827302, 0.65171249397009168, 0.68692715870718768]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.56295224312590453, 0.65508924264351187, 0.69512783405692236]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.55764592378195854, 0.65557163531114326, 0.69416304872165946]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.56777616980221901, 0.66859623733719242, 0.70429329474191993]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.56054027978774723, 0.65219488663772307, 0.69416304872165946]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.56777616980221901, 0.66087795465508925, 0.68982151471297637]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.55233960443801255, 0.64399421128798839, 0.68596237337192478]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.56005788712011573, 0.65123010130246017, 0.68933912204534487]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.57694163048721658, 0.66521948866377234, 0.69850458273034255]\n",
      "Training Size: 1000, Accuracy @1, 5, 10: [0.56054027978774723, 0.65315967197298597, 0.68982151471297637]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.56614292954891032, 0.66092245311708053, 0.69336036492650788]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.56259503294475421, 0.65129244804865682, 0.69031931069437402]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.56208819057273185, 0.65788139888494679, 0.69488089204257475]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.5676634566649772, 0.65179929042067919, 0.69082615306639639]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.57070451089711105, 0.65636087176887992, 0.6943740496705525]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.5615813482007096, 0.66345666497719213, 0.69842878864673086]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.56056766345666498, 0.65788139888494679, 0.69690826153066399]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.5712113532691333, 0.66092245311708053, 0.69893563101875322]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.55854029396857574, 0.65129244804865682, 0.6893056259503294]\n",
      "Training Size: 1100, Accuracy @1, 5, 10: [0.57678661936137865, 0.66649771920932588, 0.7040040547389762]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.5621996796583022, 0.65189535504538176, 0.69460758142018153]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.55419113721302726, 0.64548852108916177, 0.68873465029364656]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.57394554191137215, 0.65509877202349176, 0.69353977576081149]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.56273358248798722, 0.64869193806727177, 0.68553123331553656]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.57981847303790712, 0.66951414842498669, 0.70581954084356646]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.56006406833956224, 0.65563267485317667, 0.69674319273892149]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.55739455419113726, 0.66684463427656171, 0.70208222103577145]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.56860651361452219, 0.66577682861719167, 0.70315002669514148]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.56593699946609721, 0.66364121729845171, 0.69781099839829153]\n",
      "Training Size: 1200, Accuracy @1, 5, 10: [0.56540309663641219, 0.65242925787506678, 0.69300587293112659]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.57529610829103217, 0.66553863508178224, 0.70614777213761981]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.56232374506486182, 0.65820642978003385, 0.70614777213761981]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.55724760293288211, 0.65933446136491825, 0.69261139311900732]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.56796390298928368, 0.65707839819514946, 0.69994359842075582]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.5707839819514946, 0.65877044557247599, 0.69768753525098703]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.56119571347997743, 0.66328257191201356, 0.69825155104342918]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.56288776085730396, 0.65820642978003385, 0.70050761421319796]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.57021996615905246, 0.6638465877044557, 0.69994359842075582]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.5769881556683587, 0.67005076142131981, 0.70671178793006206]\n",
      "Training Size: 1300, Accuracy @1, 5, 10: [0.57191201353637899, 0.67061477721376195, 0.70389170896785114]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.56664674237895996, 0.65750149432157801, 0.69695158398087265]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.57023311416616851, 0.66766288105200244, 0.71069934249850564]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.56903765690376573, 0.66108786610878656, 0.70292887029288698]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.56485355648535562, 0.65451285116557079, 0.69336521219366409]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.56664674237895996, 0.66108786610878656, 0.70531978481769275]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.55827854154213985, 0.65032875074716079, 0.69814704124327553]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.56784219964136284, 0.66586969515839811, 0.70950388523610286]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.58577405857740583, 0.66527196652719667, 0.70651524208009564]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.57561267184698151, 0.66049013747758523, 0.69396294082486554]\n",
      "Training Size: 1400, Accuracy @1, 5, 10: [0.56365809922295274, 0.65750149432157801, 0.69216975493126121]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.55880483153210425, 0.65670692943420217, 0.69675778766687857]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.57596948506039414, 0.66369993642720915, 0.70057215511760962]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.58423394787031147, 0.6649713922441195, 0.70120788302606485]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.58359821996185635, 0.66433566433566438, 0.70184361093452008]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.55880483153210425, 0.6649713922441195, 0.70756516211061671]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.56897647806738716, 0.66179275270184357, 0.70438652256834078]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.57088366179275274, 0.65797838525111252, 0.69930069930069927]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.56834075015893193, 0.65797838525111252, 0.69866497139224415]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.57469802924348379, 0.6624284806102988, 0.70311506675143043]\n",
      "Training Size: 1500, Accuracy @1, 5, 10: [0.58041958041958042, 0.67705022250476798, 0.71265098537825811]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.56687033265444675, 0.66191446028513234, 0.69721656483367278]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.57501697216564829, 0.66734555329260015, 0.70739986422267487]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.570264765784114, 0.65987780040733202, 0.69178547182620498]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.57365919891378137, 0.66938221317040059, 0.70604209097080783]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.55940257976917851, 0.66530889341479971, 0.69585879158180586]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.5695858791581806, 0.65852002715546498, 0.69382213170400542]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.58044806517311609, 0.67277664630006784, 0.70332654446707399]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.57501697216564829, 0.66938221317040059, 0.70739986422267487]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.5695858791581806, 0.64765784114052949, 0.68771215207060421]\n",
      "Training Size: 1600, Accuracy @1, 5, 10: [0.58044806517311609, 0.66734555329260015, 0.71011541072640871]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.57392571012381643, 0.66788055353241083, 0.70429715950473415]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.57392571012381643, 0.67152221412964308, 0.70721048798252006]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.56591405680990536, 0.66278222869628556, 0.70866715222141297]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.57829570284049525, 0.66860888565185728, 0.70065549890750178]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.5637290604515659, 0.65841223597960674, 0.69410050983248361]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.58630735615440643, 0.67443554260742899, 0.71595047341587759]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.5651857246904588, 0.66496722505462491, 0.70939548434085942]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.56300072833211945, 0.66423889293517846, 0.7050254916241806]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.5637290604515659, 0.66132556445739255, 0.69701383831026953]\n",
      "Training Size: 1700, Accuracy @1, 5, 10: [0.58048069919883472, 0.67807720320466136, 0.70939548434085942]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.55852317360565595, 0.65593087195600941, 0.69442262372348784]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.57659073055773757, 0.67714061272584447, 0.70856245090337788]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.58758837391987429, 0.67242733699921442, 0.71170463472113121]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.58208955223880599, 0.67085624509033781, 0.70463472113118619]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.56166535742340928, 0.65278868813825608, 0.68813825608798118]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.58601728201099768, 0.67714061272584447, 0.70934799685781613]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.57894736842105265, 0.67085624509033781, 0.71249018067556957]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.5930871956009427, 0.68656716417910446, 0.72348782403770617]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.58601728201099768, 0.67164179104477617, 0.70149253731343286]\n",
      "Training Size: 1800, Accuracy @1, 5, 10: [0.57973291437549102, 0.66614296936370776, 0.69442262372348784]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.57033248081841437, 0.66666666666666663, 0.69906223358908781]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.55072463768115942, 0.65899403239556698, 0.69820971867007675]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.57800511508951402, 0.6675191815856778, 0.70417732310315428]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.56692242114237001, 0.66410912190963345, 0.71440750213128734]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.57800511508951402, 0.67263427109974427, 0.71270247229326511]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.55839727195225919, 0.65558397271952262, 0.69906223358908781]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.57118499573742543, 0.65984654731457804, 0.70332480818414322]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.58141517476555837, 0.67263427109974427, 0.7152600170502984]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.59249786871270249, 0.67263427109974427, 0.71099744245524299]\n",
      "Training Size: 1900, Accuracy @1, 5, 10: [0.57289002557544755, 0.67092924126172204, 0.70332480818414322]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.5610438024231128, 0.66262814538676607, 0.6952469711090401]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.56756756756756754, 0.66821994408201302, 0.70270270270270274]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.57781919850885366, 0.66169617893755828, 0.69711090400745568]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.56197576887232059, 0.66076421248835038, 0.70270270270270274]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.56477166821994407, 0.65517241379310343, 0.70363466915191053]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.56943150046598323, 0.66449207828518175, 0.69711090400745568]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.57875116495806156, 0.67753960857409135, 0.7204100652376515]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.60111835973904937, 0.67940354147250703, 0.71761416589002791]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.55638397017707364, 0.66356011183597385, 0.69897483690587137]\n",
      "Training Size: 2000, Accuracy @1, 5, 10: [0.59086672879776325, 0.66449207828518175, 0.69804287045666358]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.56320657759506676, 0.66392600205549845, 0.69886947584789316]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.58684480986639265, 0.6690647482014388, 0.69784172661870503]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.56217882836587874, 0.65775950668036998, 0.69784172661870503]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.55292908530318607, 0.6515930113052415, 0.68961973278520039]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.57759506680369987, 0.67214799588900309, 0.70914696813977385]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.58376156217882835, 0.67625899280575541, 0.71736896197327849]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.57656731757451185, 0.68036998972250773, 0.71839671120246662]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.6166495375128469, 0.69373072970195271, 0.73381294964028776]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.57862281603288801, 0.67112024665981496, 0.71839671120246662]\n",
      "Training Size: 2100, Accuracy @1, 5, 10: [0.59712230215827333, 0.68756423432682423, 0.72867420349434742]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.56930126002290948, 0.6563573883161512, 0.69988545246277201]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.57846506300114553, 0.68384879725085912, 0.72164948453608246]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.58190148911798401, 0.66895761741122561, 0.71019473081328754]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.57159221076746847, 0.67353951890034369, 0.71935853379152348]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.57502863688430694, 0.66666666666666663, 0.70904925544100805]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.58533791523482248, 0.68499427262313861, 0.73195876288659789]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.57502863688430694, 0.66437571592210765, 0.71248568155784653]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.56357388316151202, 0.65750286368843069, 0.69759450171821302]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.57617411225658643, 0.67926689576174115, 0.71821305841924399]\n",
      "Training Size: 2200, Accuracy @1, 5, 10: [0.59335624284077892, 0.67926689576174115, 0.7170675830469645]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.57309184993531692, 0.65588615782664939, 0.68046571798188871]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.58214747736093142, 0.67529107373868047, 0.71021992238033638]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.55368693402328595, 0.65200517464424323, 0.68952134540750321]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.57438551099611901, 0.67141009055627421, 0.7166882276843467]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.59249676584734801, 0.67399741267787838, 0.72186287192755494]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.57050452781371286, 0.66106080206985773, 0.70504527813712803]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.58214747736093142, 0.6727037516170763, 0.71151358344113846]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.57179818887451483, 0.66235446313065982, 0.70633893919793012]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.58344113842173351, 0.67787839586028464, 0.72186287192755494]\n",
      "Training Size: 2300, Accuracy @1, 5, 10: [0.58990944372574383, 0.68175937904269079, 0.72445019404915911]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.57800891530460619, 0.6731054977711739, 0.71322436849925708]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.55869242199108471, 0.65973254086181277, 0.69390787518573549]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.57503714710252596, 0.65676077265973254, 0.69242199108469538]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.58246656760772664, 0.68202080237741458, 0.71471025260029719]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.60326894502228823, 0.68647845468053492, 0.72808320950965821]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.58692421991084698, 0.67161961367013367, 0.71173848439821696]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.59583952451708766, 0.69390787518573549, 0.7265973254086181]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.59732540861812777, 0.69093610698365526, 0.73105497771173844]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.57206537890044573, 0.67459138187221401, 0.70579494799405651]\n",
      "Training Size: 2400, Accuracy @1, 5, 10: [0.56315007429420505, 0.64041604754829118, 0.70282317979197617]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.60558464223385688, 0.68935427574171027, 0.7172774869109948]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.60558464223385688, 0.68237347294938921, 0.72076788830715532]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.59336823734729494, 0.68237347294938921, 0.72600349040139611]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.59685863874345546, 0.67190226876090753, 0.70331588132635248]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.56893542757417104, 0.6631762652705061, 0.69458987783595116]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.56369982547993014, 0.65794066317626532, 0.69982547993019195]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.56195462478184988, 0.63874345549738221, 0.67713787085514832]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.56719022687609078, 0.66666666666666663, 0.70680628272251311]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.56195462478184988, 0.64223385689354273, 0.68411867364746948]\n",
      "Training Size: 2500, Accuracy @1, 5, 10: [0.5706806282722513, 0.66666666666666663, 0.69633507853403143]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.65961945031712477, 0.73572938689217759, 0.76744186046511631]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.55813953488372092, 0.66173361522198737, 0.71035940803382669]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.58350951374207183, 0.67230443974630016, 0.71035940803382669]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.57716701902748413, 0.66173361522198737, 0.69767441860465118]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.57716701902748413, 0.67230443974630016, 0.71247357293868918]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.59196617336152224, 0.70613107822410148, 0.7378435517970402]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.56659619450317122, 0.64270613107822405, 0.68710359408033828]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.60253699788583515, 0.67653276955602537, 0.70401691331923888]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.60042283298097254, 0.68710359408033828, 0.72304439746300209]\n",
      "Training Size: 2600, Accuracy @1, 5, 10: [0.60465116279069764, 0.70190274841437628, 0.72304439746300209]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.58713136729222515, 0.65951742627345844, 0.70777479892761397]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.58713136729222515, 0.67292225201072386, 0.70509383378016088]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.58981233243967823, 0.68632707774798929, 0.72922252010723865]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.579088471849866, 0.64611260053619302, 0.6836461126005362]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.60053619302949057, 0.68632707774798929, 0.72117962466487939]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.60321715817694366, 0.67828418230563003, 0.71581769436997322]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.60053619302949057, 0.6836461126005362, 0.72117962466487939]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.57640750670241292, 0.68096514745308312, 0.71313672922252014]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.56568364611260058, 0.66219839142091153, 0.68632707774798929]\n",
      "Training Size: 2700, Accuracy @1, 5, 10: [0.60589812332439674, 0.70777479892761397, 0.74530831099195716]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.58974358974358976, 0.68498168498168499, 0.69963369963369959]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.56776556776556775, 0.67032967032967028, 0.71062271062271065]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.5641025641025641, 0.65934065934065933, 0.70329670329670335]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.59340659340659341, 0.68498168498168499, 0.71062271062271065]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.61172161172161177, 0.68498168498168499, 0.7142857142857143]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.60439560439560436, 0.68131868131868134, 0.7216117216117216]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.60073260073260071, 0.68864468864468864, 0.7289377289377289]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.52380952380952384, 0.63003663003663002, 0.69230769230769229]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.61904761904761907, 0.7142857142857143, 0.73626373626373631]\n",
      "Training Size: 2800, Accuracy @1, 5, 10: [0.5641025641025641, 0.65567765567765568, 0.70329670329670335]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.53757225433526012, 0.61271676300578037, 0.67630057803468213]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.62427745664739887, 0.71098265895953761, 0.7225433526011561]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.5722543352601156, 0.67052023121387283, 0.71098265895953761]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.58959537572254339, 0.64739884393063585, 0.7052023121387283]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.52023121387283233, 0.60115606936416188, 0.64161849710982655]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.61271676300578037, 0.7167630057803468, 0.75144508670520227]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.58381502890173409, 0.69364161849710981, 0.74566473988439308]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.62427745664739887, 0.68786127167630062, 0.73410404624277459]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.56069364161849711, 0.65895953757225434, 0.69364161849710981]\n",
      "Training Size: 2900, Accuracy @1, 5, 10: [0.58381502890173409, 0.67052023121387283, 0.7167630057803468]\n"
     ]
    }
   ],
   "source": [
    "# Find the words closest to the transformed vector\n",
    "def top_translations(w, translation_matrix, topn=5):\n",
    "    vec = model_nl[w].dot(translation_matrix)\n",
    "    \n",
    "    return [i[0] for i in model_en.most_similar([vec], topn=topn)]\n",
    "\n",
    "def get_rank(nn, gold):\n",
    "    for idx, word in enumerate(nn):\n",
    "        if word in gold:\n",
    "            return idx + 1\n",
    "    return idx + 1\n",
    "\n",
    "def strip_accents(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', unicode(s, \"utf-8\"))\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean(dirty):\n",
    "    # Make alphanumeric characters simpler\n",
    "    clean = strip_accents(dirty)\n",
    "    # Remove all remaining weird characters\n",
    "    return re.sub('[\\W_]+', '', clean)\n",
    "\n",
    "# print out source word and translation\n",
    "def get_data():    \n",
    "    # A map that contains an array of possible translations ('target's) for a source word\n",
    "    translations = {}\n",
    "\n",
    "    # Read the training data file\n",
    "    train_data = read_dict('dutch2.txt')\n",
    "    for source, target in train_data:\n",
    "        # Only process if the models know these words\n",
    "        if source in model_nl and target in model_en and not ' ' in source and not ' ' in target:\n",
    "            if source in translations:\n",
    "                translations[source].append(target)\n",
    "            else:\n",
    "                translations[source] = [target]\n",
    "\n",
    "    # Read the CSV file\n",
    "    word_pairs = codecs.open('did_it_work.csv', 'r', 'utf-8')\n",
    "    dic2 = pd.read_csv(word_pairs, sep=';', header=None, names=['en', 'nl', 'drop', 'drop', 'drop', 'drop', 'drop'])[['en', 'nl']]\n",
    "\n",
    "    for n in range(len(dic2['nl'])):\n",
    "        source = dic2['nl'][n]\n",
    "        target = dic2['en'][n]\n",
    "\n",
    "        if source in model_nl and target in model_en and not ' ' in source and not ' ' in target:\n",
    "            if source in translations:\n",
    "                translations[source].append(target)\n",
    "            else:\n",
    "                translations[source] = [target]\n",
    "\n",
    "    # Now transform it from a dict to an array\n",
    "    return [(source, translations[source]) for source in translations]\n",
    "\n",
    "def get_translation_matrix(translations, printing=True):\n",
    "    matrix_train_source = []\n",
    "    matrix_train_target = []\n",
    "\n",
    "    for (source, targets) in translations: \n",
    "        for target in targets:\n",
    "            matrix_train_source.append(model_nl[source])\n",
    "            matrix_train_target.append(model_en[target])\n",
    "\n",
    "    # Matrix W is given in  http://stackoverflow.com/questions/27980159/fit-a-linear-transformation-in-python\n",
    "    # translation_matrix = np.linalg.pinv(matrix_train_source).dot(matrix_train_target).T\n",
    "    translation_matrix = np.linalg.lstsq(matrix_train_source, matrix_train_target, -1)[0]\n",
    "\n",
    "    return translation_matrix\n",
    "    \n",
    "\n",
    "def benchmark(translations, translation_matrix, topn, printing=True):\n",
    "    correct = np.zeros(len(topn))\n",
    "    test = 0\n",
    "    topn.sort()\n",
    "    \n",
    "    for (source, targets) in translations: \n",
    "        test = test + 1\n",
    "\n",
    "        answers = top_translations(source, translation_matrix, max(topn)) # check for largest element in the list\n",
    "        \n",
    "        # Now check at what position the best translation is\n",
    "        # (For each target in targets, check what position it's in in the answers, and take the one with the lowest index)\n",
    "        best_position = min([(answers.index(target) if target in answers else max(topn) + 1) for target in targets])\n",
    "\n",
    "        for i, n in enumerate(topn):\n",
    "            if best_position <= n:\n",
    "                correct[i] = correct[i] + 1\n",
    "                \n",
    "        if printing:\n",
    "            print \"Correct translations:  %s\" % targets\n",
    "            print \"Answered by algorithm: %s\" % answers\n",
    "            print \"Best translation at position: %s\" % best_position\n",
    "    \n",
    "    accuracy = [c / test for c in correct]\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "def display_translations(training_size=1500, topn=[1, 5, 10], printing=True):\n",
    "    # Get an array of inputs with their\n",
    "    translations = get_data()\n",
    "    if printing:\n",
    "        print \"Dataset size: %s\" % len(translations)\n",
    "\n",
    "    # Let's shuffle the pairs, so we don't always have the same training/test set\n",
    "    random.shuffle(translations)\n",
    "\n",
    "    if training_size > len(translations):\n",
    "        print 'Training size cannot be larger than total dataset size (out of bounds exception)'\n",
    "        exit()\n",
    "\n",
    "    training_set = translations[:training_size]\n",
    "    test_set = translations[training_size:]\n",
    "\n",
    "    matrix = get_translation_matrix(training_set, printing)\n",
    "    # print \"Finished computing translation matrix\"\n",
    "\n",
    "    return benchmark(test_set, matrix, topn, printing)\n",
    "\n",
    "accuracies = {}\n",
    "for i in range(500, 3000, 100):\n",
    "    for n in xrange(10):\n",
    "        accuracies[i] = display_translations(training_size=i, printing=False)\n",
    "        print \"Training Size: %s, Accuracy @1, 5, 10: %s\" % (i, accuracies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
